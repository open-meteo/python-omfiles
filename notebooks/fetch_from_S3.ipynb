{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff0cb94-8f61-45dc-9204-5175ba4815af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import time\n",
    "from enum import Enum\n",
    "from typing import Tuple\n",
    "\n",
    "import fsspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import omfiles\n",
    "from s3fs import S3FileSystem\n",
    "\n",
    "\n",
    "class SupportedDomain(Enum):\n",
    "    dwd_icon_d2 = \"dwd_icon_d2\"\n",
    "    ecmwf_ifs025 = \"ecmwf_ifs025\"\n",
    "\n",
    "    def file_length(self):\n",
    "        \"\"\"Return the number of timesteps in a single chunk file\"\"\"\n",
    "        if self == SupportedDomain.dwd_icon_d2:\n",
    "            return 121\n",
    "        elif self == SupportedDomain.ecmwf_ifs025:\n",
    "            return 104\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported domain {self}\")\n",
    "\n",
    "    def lat_lon_grid(self) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Return the latitude and longitude arrays for the domain\"\"\"\n",
    "        if self == SupportedDomain.dwd_icon_d2:\n",
    "            # DWD ICON D2 is regularized during download to nx: 1215, ny: 721 points\n",
    "            lat_start = 43.18\n",
    "            lat_step_size = 0.02\n",
    "            lat_steps = 746\n",
    "            lon_start = -3.94\n",
    "            lon_step_size = 0.02\n",
    "            lon_steps = 1215\n",
    "            lat = np.linspace(lat_start, lat_start + lat_step_size * lat_steps, lat_steps, endpoint=False)\n",
    "            lon = np.linspace(lon_start, lon_start + lon_step_size * lon_steps, lon_steps, endpoint=False)\n",
    "            return lat, lon\n",
    "        elif self == SupportedDomain.ecmwf_ifs025:\n",
    "            # ECMWF IFS grid is a regular global lat/lon grid\n",
    "            lat = np.linspace(-90, 90, 721, endpoint=True)\n",
    "            lon = np.linspace(-180, 180, 1440, endpoint=False)\n",
    "            return lat, lon\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported domain {self}\")\n",
    "\n",
    "\n",
    "class SupportedVariable(Enum):\n",
    "    temperature_2m = \"temperature_2m\"\n",
    "\n",
    "\n",
    "def find_chunk_for_timestamp(target_time: datetime.datetime, domain: SupportedDomain) -> Tuple[int, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Find the chunk number that contains a specific timestamp.\n",
    "\n",
    "    Args:\n",
    "        target_time: The timestamp to find\n",
    "        domain: The domain to search in\n",
    "\n",
    "    Returns:\n",
    "        Tuple containing the chunk number and the time range of the chunk\n",
    "    \"\"\"\n",
    "    meta_file = f\"openmeteo/data/{domain.value}/static/meta.json\"\n",
    "    # Load metadata from S3\n",
    "    fs = fsspec.filesystem(protocol=\"s3\", anon=True)\n",
    "    with fs.open(meta_file, mode=\"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    # Get domain-specific parameters\n",
    "    dt_seconds = metadata[\"temporal_resolution_seconds\"]\n",
    "    om_file_length = domain.file_length()\n",
    "\n",
    "    # Calculate seconds since epoch for the target time\n",
    "    epoch = datetime.datetime(1970, 1, 1)\n",
    "    target_seconds = int((target_time - epoch).total_seconds())\n",
    "\n",
    "    # Calculate the chunk number\n",
    "    chunk = target_seconds // (om_file_length * dt_seconds)\n",
    "\n",
    "    # Calculate the timerange for the chunk\n",
    "    chunk_start = np.datetime64(epoch + datetime.timedelta(0, chunk * om_file_length * dt_seconds))\n",
    "    chunk_end = np.datetime64(epoch + datetime.timedelta(0, (chunk + 1) * om_file_length * dt_seconds))\n",
    "    print(f\"Chunk {chunk} covers the timerange from {chunk_start} to {chunk_end}\")\n",
    "    dt_range = np.arange(\n",
    "        chunk_start, chunk_end, np.timedelta64(datetime.timedelta(0, dt_seconds)), dtype=\"datetime64[s]\"\n",
    "    )\n",
    "\n",
    "    return chunk, dt_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd96629a-0429-4df3-b0c8-32473f63aac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    # Setup parameters\n",
    "    domain = SupportedDomain.dwd_icon_d2\n",
    "    variable = SupportedVariable.temperature_2m\n",
    "    timestamp = datetime.datetime(2025, 2, 1, 12, 0)\n",
    "\n",
    "    # Get domain information\n",
    "    chunk_num, timerange = find_chunk_for_timestamp(timestamp, domain)\n",
    "    lat, lon = domain.lat_lon_grid()\n",
    "    s3_file = f\"openmeteo/data/{domain.value}/{variable.value}/chunk_{chunk_num}.om\"\n",
    "\n",
    "    print(f\"Accessing file: {s3_file}\")\n",
    "    print(f\"Grid dimensions: lat={len(lat)}, lon={len(lon)}\")\n",
    "\n",
    "    # Define a region of interest (subset of data to extract)\n",
    "    start_lat_idx, end_lat_idx = 200, 300  # Example slice\n",
    "    start_lon_idx, end_lon_idx = 400, 500  # Example slice\n",
    "    time_idx = 0  # First timestamp in the chunk\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Configure S3 filesystem with mmap cache\n",
    "    fs_async = S3FileSystem(anon=True, default_block_size=256, default_cache_type=\"none\")\n",
    "    # fs_async = CachingFileSystem(fs=s3_fs, cache_check=3600, block_size=256, cache_storage=\"cache\", check_files=False, same_names=True)\n",
    "\n",
    "    # Initialize the concurrent reader\n",
    "    reader_async = await omfiles.OmFilePyReaderAsync.from_fsspec(fs_async, s3_file)\n",
    "    print(f\"Data shape: {reader_async.shape}\")\n",
    "\n",
    "    # Extract data slice concurrently\n",
    "    data = await reader_async.read_concurrent(\n",
    "        (slice(start_lat_idx, end_lat_idx), slice(start_lon_idx, end_lon_idx), slice(time_idx, time_idx + 1))\n",
    "    )\n",
    "    # data = data[:,:,0]  # Remove time dimension\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Data fetching time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    # Extract the actual lat/lon values for this region\n",
    "    region_lat = lat[start_lat_idx:end_lat_idx]\n",
    "    region_lon = lon[start_lon_idx:end_lon_idx]\n",
    "\n",
    "    # Create meshgrid for plotting\n",
    "    lon_grid, lat_grid = np.meshgrid(region_lon, region_lat)\n",
    "\n",
    "    # Visualize the data\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.contourf(lon_grid, lat_grid, data, cmap=\"RdBu_r\", levels=20)\n",
    "    plt.colorbar(label=\"Temperature (°C)\")\n",
    "    plt.title(f\"Temperature at 2m - {timerange[time_idx]}\")\n",
    "    plt.xlabel(\"Longitude (°)\")\n",
    "    plt.ylabel(\"Latitude (°)\")\n",
    "    plt.grid(linestyle=\"--\", alpha=0.5)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Run the async function\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c5bb0e-ed4b-4c11-9a60-2f819f2896a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
